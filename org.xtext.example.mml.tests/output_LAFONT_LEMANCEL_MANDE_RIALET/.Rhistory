library(readr)
library(caret)
library(randomForest)
library(LogicReg)
library(e1071)
library(party)
data <- read.csv("output_LAFONT_LEMANCEL_MANDE_RIALET/iris.csv")
predictive <- names(data[dim(data)[2]])
predictors <- "."
formula <- reformulate(termlabels = predictors, response = predictive)
split=0.35
trainIndex <- createDataPartition(data[[predictive]], p=split, list=FALSE)
data_train <- data[ trainIndex,]
data_test <- data[-trainIndex,]
fitControl <- trainControl(method="none")
model <- train(formula, data=data_train,method="rf",trControl=fitControl)
pred <- predict(model,newdata=data_test)
u <- union(pred, data_test[[predictive]])
t <- table(factor(pred, u), factor(data_test[[predictive]], u))
mat <- confusionMatrix(t)
print("Balanced Accuracy")
if (!is.null(dim(mat$byClass)[1])) { print(mean(mat$byClass[,"Balanced Accuracy"])) } else { print(mean(mat$byClass["Balanced Accuracy"])) }
print("Recall")
if (!is.null(dim(mat$byClass)[1])) { print(mean(mat$byClass[,"Recall"],na.rm=TRUE)) } else { print(mean(mat$byClass["Recall"],na.rm=TRUE)) }
print("Precision")
if (!is.null(dim(mat$byClass)[1])) { print(mean(mat$byClass[,"Precision"],na.rm=TRUE)) } else { print(mean(mat$byClass["Precision"],na.rm=TRUE)) }
print("F1")
if (!is.null(dim(mat$byClass)[1])) { print(mean(mat$byClass[,"F1"],na.rm=TRUE)) } else { print(mean(mat$byClass["F1"],na.rm=TRUE)) }
print("Accuracy")
print(mat$overall["Accuracy"])
print("Macro Recall non supportÃ©")
print("Macro Precision non supportÃ©")
print("Macro F1 non supportÃ©")
print("Macro Accuracy non supportÃ©")
library(readr)
library(caret)
library(randomForest)
library(LogicReg)
library(e1071)
library(party)
data <- read.csv("C:/Users/Yohann/Documents/IDM/Projet/MML-classification/org.xtext.example.mml.tests/output_LAFONT_LEMANCEL_MANDE_RIALET/iris.csv")
predictive <- names(data[dim(data)[2]])
predictors <- "."
formula <- reformulate(termlabels = predictors, response = predictive)
split=0.35
trainIndex <- createDataPartition(data[[predictive]], p=split, list=FALSE)
data_train <- data[ trainIndex,]
data_test <- data[-trainIndex,]
fitControl <- trainControl(method="none")
model <- train(formula, data=data_train,method="rf",trControl=fitControl)
pred <- predict(model,newdata=data_test)
u <- union(pred, data_test[[predictive]])
t <- table(factor(pred, u), factor(data_test[[predictive]], u))
mat <- confusionMatrix(t)
print("Balanced Accuracy")
if (!is.null(dim(mat$byClass)[1])) { print(mean(mat$byClass[,"Balanced Accuracy"])) } else { print(mean(mat$byClass["Balanced Accuracy"])) }
print("Recall")
if (!is.null(dim(mat$byClass)[1])) { print(mean(mat$byClass[,"Recall"],na.rm=TRUE)) } else { print(mean(mat$byClass["Recall"],na.rm=TRUE)) }
print("Precision")
if (!is.null(dim(mat$byClass)[1])) { print(mean(mat$byClass[,"Precision"],na.rm=TRUE)) } else { print(mean(mat$byClass["Precision"],na.rm=TRUE)) }
print("F1")
if (!is.null(dim(mat$byClass)[1])) { print(mean(mat$byClass[,"F1"],na.rm=TRUE)) } else { print(mean(mat$byClass["F1"],na.rm=TRUE)) }
print("Accuracy")
print(mat$overall["Accuracy"])
print("Macro Recall non supportÃ©")
print("Macro Precision non supportÃ©")
print("Macro F1 non supportÃ©")
print("Macro Accuracy non supportÃ©")
print(mat)
print(mat$overall)
print(mat$overall.accuracy)
print(mat$overall.Accuracy)
overall <- mat$overall
overall.accuracy
overall.accuracy <- overall['Accuracy']
overall.accuracy
overall.accuracy.attributes
attributes(overall.accuracy)
attributes(overall.accuracy["Accuracy"])
overall.accuracy["Accuracy"]
print(overall.accuracy["Accuracy"])
print(overall.accuracy['Accuracy'])
print(overall)
accu <- overall.accuracy['Accuracy']
accu
attributes(accu)
str(accu)
str(accu)
as.double(accu)
paste("Today is", date())
paste("A", 1:6, sep = "")
